# Redfin_EMR_S3-project
Data Engineering project using Redfin as Data Source, AWS EMR, VPC, JupyterNotebook, PySpark, and s3 bucket
I explored Amazon EMR (Elastic MapReduce) and its benefits in processing big data. I first created a VPC and then an EMR cluster within that VPC. Later, I created Amazon EMR studio and Jupyterlab after which I attached the Jupyter notebook to the provisioned cluster. Then write the Pyspark code in the Jupyter notebook attached to the provisioned EMR to extract data from the Redfin data source, process it, and load the transformed data as a parquet file into an S3 bucket.
<img width="661" alt="Screenshot 2023-12-29 235749" src="https://github.com/RitikArora24/Redfin_EMR_S3-project/assets/129395292/49a021c3-1976-4e80-8b87-ec525c6015e3">
